{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6337743-2e1a-4c9a-8352-2ddfa0db3a51",
   "metadata": {},
   "source": [
    "### Importamos ciertas librerias necesarias para realizar scraping con respecto a los productos en la RD que se encuentran en el dataset de Open Food Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3898dbe1-c73d-4a46-b6dd-aa0270644525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67546ca-72d1-40ba-9936-96bd31eef889",
   "metadata": {},
   "source": [
    "### Realizamos el scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688cb2f8-f808-417d-a811-5157ead0649d",
   "metadata": {},
   "source": [
    "## Prueba del modelo sin entrenamiento previo\n",
    "\n",
    "### Importaciones y configuración global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f185294-633a-4b9d-ab7f-cd2bb5f715c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Union, Tuple\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "# Configuraciones globales\n",
    "BASE_URL = \"http://localhost:11434/api/generate\"\n",
    "MODEL_NAME = \"llama3.2-vision\"\n",
    "VALID_CLASSES = ['agua', 'leche', 'galletas']\n",
    "BRANDS = {\n",
    "    'agua': ['planeta azul', 'dasani', 'cascada'],\n",
    "    'leche': ['carnation', 'rica', 'nestlé', 'milex'],\n",
    "    'galletas': ['club social', 'oreo', 'club extra', 'guarina']\n",
    "}\n",
    "ERROR_CLASS = 'desconocido'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b5c25-b1db-4dc6-9aab-1293d9d8db1a",
   "metadata": {},
   "source": [
    "### Funciones de procesamiento de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9289cc19-35e0-49ef-8dc7-7a993db7bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    \"\"\"Codifica una imagen a base64 con manejo mejorado de formatos.\"\"\"\n",
    "    try:\n",
    "        if isinstance(image_path, str):\n",
    "            with Image.open(image_path) as img:\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                buffer = io.BytesIO()\n",
    "                img.save(buffer, format='JPEG')\n",
    "                img_str = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "        else:\n",
    "            img = image_path\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, format='JPEG')\n",
    "            img_str = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "        \n",
    "        return img_str\n",
    "    except Exception as e:\n",
    "        print(f\"Error al codificar la imagen: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def clean_prediction(prediction: str) -> Tuple[str, str]:\n",
    "    \"\"\"Limpia la respuesta del modelo para extraer la categoría y la marca.\"\"\"\n",
    "    prediction_lower = prediction.lower()\n",
    "    \n",
    "    # Primero identificamos la categoría\n",
    "    category_scores = {clase: 0 for clase in VALID_CLASSES}\n",
    "    \n",
    "    # Palabras clave para categorías\n",
    "    keywords = {\n",
    "        'agua': ['agua', 'botella', 'bebida', 'refresco', 'líquido'],\n",
    "        'leche': ['leche', 'lácteo', 'dairy', 'milk', 'evaporada', 'condensada'],\n",
    "        'galletas': ['galleta', 'cookie', 'oreo', 'snack', 'dulce', 'club social', 'cracker', 'sandwich']\n",
    "    }\n",
    "    \n",
    "    # Evaluar categoría\n",
    "    for categoria, palabras in keywords.items():\n",
    "        for palabra in palabras:\n",
    "            if palabra in prediction_lower:\n",
    "                category_scores[categoria] += 1\n",
    "    \n",
    "    # Determinar categoría\n",
    "    category = max(category_scores.items(), key=lambda x: x[1])[0] if max(category_scores.values()) > 0 else VALID_CLASSES[0]\n",
    "    \n",
    "    # Buscar marca\n",
    "    brand = \"marca desconocida\"\n",
    "    for marca in BRANDS[category]:\n",
    "        if marca.lower() in prediction_lower:\n",
    "            brand = marca\n",
    "            break\n",
    "            \n",
    "    if brand == \"marca desconocida\":\n",
    "        common_prefixes = [\"marca\", \"producto\", \"de la marca\", \"elaborado por\"]\n",
    "        for prefix in common_prefixes:\n",
    "            if prefix in prediction_lower:\n",
    "                start_idx = prediction_lower.find(prefix) + len(prefix)\n",
    "                end_idx = prediction_lower.find(\" \", start_idx + 15) if \" \" in prediction_lower[start_idx:] else len(prediction_lower)\n",
    "                potential_brand = prediction_lower[start_idx:end_idx].strip()\n",
    "                if len(potential_brand) > 2:\n",
    "                    brand = potential_brand\n",
    "                    break\n",
    "    \n",
    "    return category, brand\n",
    "\n",
    "def analyze_image(image_path: str, prompt: str) -> str:\n",
    "    \"\"\"Analiza una imagen usando el modelo de visión.\"\"\"\n",
    "    base64_image = encode_image(image_path)\n",
    "    if not base64_image:\n",
    "        return f\"{ERROR_CLASS} (marca desconocida)\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"images\": [base64_image]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"Enviando petición a Ollama...\")\n",
    "        response = requests.post(BASE_URL, json=payload)\n",
    "        print(f\"Código de estado: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            prediction = result.get('response', 'No se pudo obtener una respuesta')\n",
    "            category, brand = clean_prediction(prediction)\n",
    "            print(f\"Predicción original: {prediction}\")\n",
    "            print(f\"Categoría: {category}\")\n",
    "            print(f\"Marca: {brand}\")\n",
    "            return f\"{category} ({brand})\"\n",
    "        else:\n",
    "            print(f\"Respuesta completa del servidor: {response.text}\")\n",
    "            return f\"{ERROR_CLASS} (marca desconocida)\"\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error detallado: {str(e)}\")\n",
    "        return f\"{ERROR_CLASS} (marca desconocida)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61082d0c-e806-4678-8ef3-a6736718072e",
   "metadata": {},
   "source": [
    "### Funciones de métricas y visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53dd5c70-3d79-4aa9-9cca-9db1f25d2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions: List[str], ground_truth: List[str]) -> Dict[str, float]:\n",
    "    \"\"\"Calcula métricas de evaluación.\"\"\"\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Limpiar predicciones para obtener solo la categoría (antes del paréntesis)\n",
    "    cleaned_predictions = [pred.split('(')[0].strip() for pred in predictions]\n",
    "    \n",
    "    y_true = le.fit_transform(ground_truth)\n",
    "    y_pred = le.transform(cleaned_predictions)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision_macro': precision_score(y_true, y_pred, average='macro'),\n",
    "        'recall_macro': recall_score(y_true, y_pred, average='macro'),\n",
    "        'f1_macro': f1_score(y_true, y_pred, average='macro')\n",
    "    }\n",
    "    \n",
    "    classes = le.classes_\n",
    "    for i, class_name in enumerate(classes):\n",
    "        y_true_binary = (y_true == i)\n",
    "        y_pred_binary = (y_pred == i)\n",
    "        \n",
    "        metrics[f'precision_{class_name}'] = precision_score(y_true_binary, y_pred_binary)\n",
    "        metrics[f'recall_{class_name}'] = recall_score(y_true_binary, y_pred_binary)\n",
    "        metrics[f'f1_{class_name}'] = f1_score(y_true_binary, y_pred_binary)\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "def plot_confusion_matrix(predictions: List[str], ground_truth: List[str]) -> None:\n",
    "    \"\"\"Genera y muestra la matriz de confusión.\"\"\"\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Limpiar predicciones para obtener solo la categoría\n",
    "    cleaned_predictions = [pred.split('(')[0].strip() for pred in predictions]\n",
    "    \n",
    "    y_true = le.fit_transform(ground_truth)\n",
    "    y_pred = le.transform(cleaned_predictions)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, \n",
    "               annot=True, \n",
    "               fmt='d', \n",
    "               cmap='Blues',\n",
    "               xticklabels=le.classes_,\n",
    "               yticklabels=le.classes_)\n",
    "    plt.title('Matriz de Confusión')\n",
    "    plt.ylabel('Etiqueta Verdadera')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c67b79-8737-4378-a872-a3aac59bc3c7",
   "metadata": {},
   "source": [
    "### Función principal de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a74c59f6-3f53-46e7-9934-310ed8503603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vision_with_metrics(image_paths: List[str], \n",
    "                           ground_truth: List[str] = None, \n",
    "                           prompt: str = None) -> Dict[str, float]:\n",
    "    \"\"\"Función de prueba que evalúa múltiples imágenes y muestra métricas.\"\"\"\n",
    "    \n",
    "    if ground_truth is None:\n",
    "        ground_truth = ['galletas'] * len(image_paths)\n",
    "    \n",
    "    if len(image_paths) != len(ground_truth):\n",
    "        print(\"ADVERTENCIA: El número de imágenes no coincide con el número de etiquetas ground truth\")\n",
    "        if len(image_paths) > len(ground_truth):\n",
    "            ground_truth.extend([ground_truth[-1]] * (len(image_paths) - len(ground_truth)))\n",
    "        else:\n",
    "            ground_truth = ground_truth[:len(image_paths)]\n",
    "    \n",
    "    if prompt is None:\n",
    "        prompt = f\"Identifica qué tipo de producto ves en esta imagen y su marca. El producto debe ser uno de estos: {', '.join(VALID_CLASSES)}. Menciona explícitamente tanto el tipo de producto como la marca, especialmente si es una marca dominicana como Planeta Azul, Club Social, Rica, etc.\"\n",
    "    \n",
    "    print(\"Ejemplos de imágenes a analizar:\")\n",
    "    for i, path in enumerate(image_paths):\n",
    "        try:\n",
    "            display(IPImage(filename=path))\n",
    "            print(f\"Ground truth: {ground_truth[i]}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al mostrar la imagen {path}: {str(e)}\")\n",
    "    \n",
    "    print(\"\\nProcesando imágenes...\")\n",
    "    predictions = []\n",
    "    \n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        print(f\"\\nProcesando imagen {i+1}/{len(image_paths)}: {image_path}\")\n",
    "        prediction = analyze_image(image_path, prompt)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    print(\"\\nResumen de predicciones:\")\n",
    "    for i, (pred, true) in enumerate(zip(predictions, ground_truth)):\n",
    "        print(f\"Imagen {i+1}: Predicción = {pred}, Ground Truth = {true}\")\n",
    "    \n",
    "    metrics = calculate_metrics(predictions, ground_truth)\n",
    "    plot_confusion_matrix(predictions, ground_truth)\n",
    "    \n",
    "    print(\"\\nMétricas de evaluación:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Celda 5: Ejecución de prueba\n",
    "image_paths = ['37_Planeta Azul.jpg', '197_leche.jpg', '4_Club Social Integral Tradicion.jpg', '7_Oreo Original.jpg', '127_Carnation Evaporated Milk.jpg']\n",
    "ground_truth = ['agua', 'leche', 'galletas', 'galletas', 'leche']\n",
    "metrics = test_vision_with_metrics(image_paths, ground_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
